# -*- coding: utf-8 -*-
"""Bank Churn Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r3t0diVipxPqfRmCVHW3Jkk2uviPHLg6
"""
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

df=pd.read_csv("C:/Users/Lenovo/Downloads/Churn_Modelling1.csv")

df.head()

df.info()

df.shape

print("Number of Rows",df.shape[0])
print("Number of Columns",df.shape[1])

df.isnull().sum()

df.describe(include='all')



"""**Define Label and Features**"""

df.columns

df = df.drop(['RowNumber', 'CustomerId', 'Surname'],axis=1)

df.head()



"""Encoding"""

df['Geography'].unique()

df= pd.get_dummies(df,drop_first=True)

df.head()

df['Exited'].value_counts()

import seaborn as sns

import matplotlib.pyplot as plt

sns.countplot(data=df, x='Exited')
plt.show()  # Display the plot

X = df.drop('Exited',axis=1)
y = df['Exited']

"""Data Handling"""

from imblearn.over_sampling import SMOTE

X_res,y_res = SMOTE().fit_resample(X,y)

y_res.value_counts()

"""Split the data"""
import sklearn


from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42)

"""Features Scaling"""

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

X_train=sc.fit_transform(X_train)
X_test = sc.transform(X_test)

X_train

"""Loistic Regression"""

from sklearn.linear_model import LogisticRegression

log = LogisticRegression()

log.fit(X_train,y_train)

y_pred1 = log.predict(X_test)

from sklearn.metrics import accuracy_score

accuracy_score(y_test,y_pred1)

from sklearn.metrics import precision_score,recall_score,f1_score

precision_score(y_test,y_pred1)

recall_score(y_test,y_pred1)

f1_score(y_test,y_pred1)

"""Support Vector Machine Classifier

SVM
"""

from sklearn import svm

svm = svm.SVC()

svm.fit(X_train,y_train)

y_pred2 = svm.predict(X_test)

accuracy_score(y_test,y_pred2)

precision_score(y_test,y_pred2)

recall_score(y_test,y_pred2)

f1_score(y_test,y_pred2)

"""KNN Classifier"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()

knn.fit(X_train,y_train)

y_pred3 = knn.predict(X_test)

accuracy_score(y_test,y_pred3)

precision_score(y_test,y_pred3)

recall_score(y_test,y_pred3)

f1_score(y_test,y_pred3)

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()

dt.fit(X_train,y_train)

DecisionTreeClassifier()

y_pred4 = dt.predict(X_test)

accuracy_score(y_test,y_pred4)

precision_score(y_test,y_pred4)

recall_score(y_test,y_pred4)

f1_score(y_test,y_pred4)

"""Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()

rf.fit(X_train,y_train)

y_pred5 = rf.predict(X_test)

accuracy_score(y_test,y_pred5)

precision_score(y_test,y_pred5)

recall_score(y_test,y_pred5)

f1_score(y_test,y_pred5)

final_data=pd.DataFrame({'Models':['LR','SVC','KNN','DT','RF'],
                        'ACC':[accuracy_score(y_test,y_pred1),
                              accuracy_score(y_test,y_pred2),
                              accuracy_score(y_test,y_pred3),
                              accuracy_score(y_test,y_pred4),
                              accuracy_score(y_test,y_pred5),]})

final_data

import seaborn as sns
import matplotlib.pyplot as plt

# Create a bar plot for 'Models' vs 'ACC'
sns.barplot(data=final_data, x='Models', y='ACC')

# Customize the plot
plt.xticks(rotation=45)
plt.tight_layout()

# Display the plot
plt.show()

final_data=pd.DataFrame({'Models':['LR','SVC','KNN','DT','RF'],
                        'PRE':[precision_score(y_test,y_pred1),
                              precision_score(y_test,y_pred2),
                              precision_score(y_test,y_pred3),
                              precision_score(y_test,y_pred4),
                              precision_score(y_test,y_pred5)]})

final_data

sns.barplot(final_data, x='Models', y='PRE')

# Customize the plot
plt.xticks(rotation=45)
plt.tight_layout()

# Display the plot
plt.show()

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(X_train,y_train)
y_pred = rf.predict(X_test)
from sklearn.metrics import accuracy_score, confusion_matrix
cm = confusion_matrix(y_test,y_pred)
print(cm)
print(accuracy_score(y_test,y_pred))

# pickling the Model
import pickle
file = open('Customer_Churn_Prediction.pkl', 'wb')
pickle.dump(rf, file)

